# [Chapter 6. 학습 관련 기술들](https://www.miricanvas.com/design/17xkq1)

## 6.3 배치 정규화

앞선 gradient를 계산하는 방법들에서 / 가중치 초깃값을 골고루 설정해야 함이 / 많이 강조되었습니다. / 그렇다면 / 초기값 선정에 있어 약간의 강제성을 띠면 어떨까. / 이런 아이디어에서 배치 정규화가 시작되었습니다.

### 6.3.1 배치 정규화 (2015, Batch Normalization)

배치 정규화는 / 학습을 빨리 진행할 수 있고, / 초깃값에 크게 의존하지 않으며, / 오버피팅을 억제할 수 있습니다. / 
이는 배치 정규화를 이용하면 / 몇 가지 골치아픈 문제를 / 고려하지 않아도 된다는 것입니다.

배치 정규화 계층은 / 활성화 함수 뒤에 넣을 수도 있지만, / 대체로 활성화 함수 연산 이전에 / 실행됩니다. / 
이 순서는 마치 / 활성화 함수로 인해 기울기 값이 / 제대로 연산되지 않는 것을 최소화하는 것처럼 보입니다.
배치 정규화 과정은 / 평균과 분산을 이용한 일반적인 정규화 과정으로 계산됩니다. /
이때 / 현재 수식으로 구해지는 값들은 / 학습을 거듭하면서 갱신하는 것이므로 / 0이 될 수도 있습니다. / 그래서 표준편차가 0이 되는 것을 방지하고자 / 작은 수를 더해주게 됩니다.

이 처리과정을 통해 / 데이터의 분포가 한쪽 값으로 덜 치우치게 합니다. / 
이런 정규화는 표준편차를 이용한 확대와 / 평균을 이용한 이동 변환을 수행하는 것이며 / 이는 어떤 값들의 선형 결합으로 표현할 수 있습니다.

### 6.3.2 배치 정규화의 효과 (test_mnist.py)

배치 정규화의 효과는 / 다음 그림을 통해 쉽게 알아볼 수 있습니다. / 
가중치의 초깃값을 / 지속적으로 줄였을 때 / 배치 정규화를 이용했을 때의 train 정확도와 / 이를 이용하지 않았을 떄의 정확도를 표시한 그림입니다. / 
배치 정규화를 이용하지 않았을 때는 주황색 선으로 / 첫줄에 3번쨰 4번째를 제외하고는 / 반복 안에 최적의 값을 찾지 못한 것으로 보입니다. / 
특정 가중치에선 아예 정확도가 오르지 않기도 했습니다. / 
그러나 배치 정규화를 이용한 파란 선을 보면 / 적은 반복 횟수 안에서 평균적으로 높은 정확도를 보입니다. / 
심지어 몇 개의 케이스는 / 정확도가 너무 높아 overfitting을 의심해야 할 정도입니다. / 
이렇듯 배치 정규화 방법은 / 빠르게 학습하며 / 초기값에 크게 영향을 받지 않는 것으로 볼 수 있습니다. 

---

## 6.4 바른 학습을 위해

지속적으로 언급했왔듯 overfitting은 자주 발생하는 문제입니다. / 특히 신경망은 층을 많이, 깊게 쌓다보니 / 과대적합이 발생하는 일이 비일비재합니다. / 그래서 overfitting을 줄이는 문제가 상당히 중요합니다. / 
이번에는 overfitting이 일어나지 않게 하고자 / train data의 정확도와 test data의 정확도의 차이를 / 줄이는 방법들에 대해 이야기하고자 합니다.

### 6.4.1 오버피팅

먼저 대체로 매개변수가 많거나, 훈련 데이터가 적은 모델에서 / 오버피팅으로 이어지는 경우가 많습니다.
이후 있을 overfitting을 줄이는 방법들에는

이런 식으로 train data에 대한 정확도를 나타내는 파란색 선은 / 일찌감치 1의 값을 갖지만, / 이와 달리 test data에 대한 정확도는 0.75에 그치는 데이터와 / 각 층의 노드가 100개이고, / ReLU를 이용한 7층 신경망을 이용해보도록 하겠습니다.

### 6.4.2 가중치 감소

예로부터 overfitting을 막고자 사용한 방법에는 / 가중치 감소라는 것이 있습니다. / 
큰 가중치에 대해 큰 패널티를 부과하는 방식으로

손실 함수에 / 가중치의 제곱합이 패널티로 들어가게 됩니다. / 
그리고 앞에 1/2를 곱하므로 / 기울기를 구할 때 lambda * W가 / 패널티로 전달되게 합니다. / 
이때 lambda는 가중치 감소에 대한 parameter로 / 이 값이 커지면 가중치 합이 loss를 계산하는 데 / 큰 영향을 주므로 / 큰 가중치를 더 작게 만들게 됩니다.

이걸 그래프로 보면 / 아직까지 차이는 있지만, / train data 정확도가 더 이상 1의 값을 갖지 않아 / test data 정확도와 전처럼 큰 차이를 보이지 않음을 알 수 있습니다.

### 6.4.3 드롭아웃

앞선 방식은 / 전체적인 모형의 매개변수를 줄이고자 했던 것이고

dropout은 학습에 이용하는 가중치를 줄여보고자 하는 방식입니다.

dropout은 원래 왼쪽처럼 구성된 신경망을 학습시킬 때는 / 오른쪽처럼 임의의 노드를 선택해 학습시킵니다. / 그리고 이후 예측에선 전체 노드를 이용하되, / 각 뉴런의 출력에 / 훈련 때 삭제 안 한 비율을 곱하여 출력합니다.

Dropout 계층을 위한 클래스 구현을 확인해보면 / 임의의 mask는 입력의 shape과 같은 형태로 구성되어야 하고 / 이를 위해 x의 shape을 이용했고, / 난수를 통해 인자의 비율보다 큰 값만 / 매개변수로 이용했습니다. / 
forward 함수에서 학습시킬 때는 Dropout의 계층마다 임의의 선택 mask가 주어지고 / 이를 통해 모형을 구성하는 매개변수를 줄인 것처럼 / 느끼게 하는 겁니다.
이것 또한 정확도에 대한 그래프를 그려보면 /

이런 형태를 보입니다. / 
이때 test 데이터에 대한 정확도는 또 줄었지만, / train data에 대한 정확도를 신뢰할 수 있음을 / 알 수 있습니다. / 
다시 말해 학습하지 않은 데이터에 대해서도 / 제대로 학습할 수 있을 것이란 약간의 믿음이 생긴 것이죠.

<!-- (앙상블 학습은 비슷한 구성이지만, 전혀 다른 기법을 이용한다는 점에서 드롭아웃과 결이 다른 편.)
추가로 앙상블 학습이란 방법이 있습니다. / 
앙상블 학습은 / 비슷한 구조지만, 다른 신경망을 각각 학습시키고 / 모형을 평가 및 이용할 때는 / 각 모형의 출력을 평균 내어 결과로 전달합니다. / 
드롭아웃이 결과적으로 하나의 모형을 이용하는 방식이라면 / 앙상블 학습은 드롭아웃을 학습시킬 때처럼 / 적은 수의 매개변수로 구성된 / 다량의 신경망을 이용한다는 차이가 있습니다. -->

---

## 6.5 적절한 하이퍼파라미터 값 찾기

사실 신경망에 신경써야 할 것은 가중치만 있는 것이 아닙니다. / 
지금까지 모형을 학습시킬 때 이용했던 / 학습률이나 dropout의 drop 비율처럼 / 신경써야 할 변수들이 그것들이죠. / 
이렇게 학습에 관여하는 (모수,) 변수들을 hyper-parameter라고 부릅니다. / 
hyper-parameter는 매우 중요하지만, / 최적의 값을 찾기란 쉽지 않습니다. / 
결과적으로 그 값을 찾아가는 작업은 / 정확도를 확인하는 작업이 될 겁니다. / 
그렇다면 어떤 데이터로 / hyper-parameter에 따른 정확도를 확인해야 할까요

### 6.5.1 검증 데이터

지금까지는 모형을 학습시킬 때 / 우리가 가진 데이터를 2가지로 분리했습니다. / 
총 데이터의 대부분으로 / 모형을 학습시키는 훈련 데이터와 / 모형의 범용 능력을 파악하는 test 데이터가 그것입니다.

이제부터는 hyper-parameter 조정을 위해 / 데이터를 세분류로 나눕니다. / 
여전히 총 데이터의 대부분을 차지하는 train 데이터와 / hyper-parameter를 평가할 validation data(or set) / 마지막으로 test 데이터입니다.

test data는 범용 능력을 평가하기 위한 것이므로 / 학습에 이용해서는 안 되기 때문에 / 이 validation data는 / 결국 train 데이터의 일부라고 볼 수 있습니다. / 
(test 데이터의 일부로 hyper-parameter의 값을 조정하면 / 결국 모형에 학습시킨 게 되어버려 Overfitting을 발생시키고, test data의 소명을 다하지 못하게 됩니다.) 

따라서 validation data은 / 대략적으로 train data의 20%를 분리해 사용합니다.

### 6.5.2 하이퍼파라미터 최적화

(나아가) 최적의 hyper-parameter 값을 찾는 것은 / 최적 값이 존재하는 범위를 조금씩 줄여나가며 찾게 됩니다. / 

이것은 다음에 있을 코드의 출력값 중 일부인데요, / 현재 학습률과 가중치 감소 값, / 그리고 그에 대한 정확도를 출력한 것입니다. / 
이 값들을 보면 정확도를 높이는 데 영향을 준 것이 / 학습률의 상승인지 가중치 감소 변수의 상승인지 명확히 알 수 없습니다. / 또 얼만큼 변해야 하는지도 알기 어렵습니다. /
이렇게 최종 정확도에 미치는 영향이 / hyper-parameter마다 다르기 때문에 / 최적의 hyper-parameter 쌍이 있을 공간으로 / 줄여나가는 게 더 좋은 결과를 줍니다.

따라서 초기 hyper-parameter의 범위를 대략적으로 지정하는 것이 효과적이며 / (0.001, 1000)과 같이 10의 거듭제곱 단위로 범위를 지정합니다. / 
이를 log scale로 지정한다고 표현합니다.

<!-- 더불어 딥러닝은 학습에 오랜 시간이 걸리기 때문에 / 나쁠 듯한 값은 일찍 포기하는 것이 좋고, / 
tarin, test에 대한 정확도를 구할 때 / 값을 저장하는 주기가 되는 에폭 또한 되도록 작게 설정합니다. -->

정리해보자면 hyper-parameter를 갱신하는 과정은 / 대략적으로 값의 범위를 설정하고 / 범위 안에서 무작위로 추출해 이용하며 / 검증 데이터에 대한 정확도를 계산하고 / 이를 반복하면서 hyper-parameter의 범위를 갱신합니다.
이 작업을 반복하다가 적당한 범위를 구하면 / 하나의 값을 선택해 hyper-parameter 값을 결정하게 됩니다.

### 6.5.3 하이퍼파라미터 최적화 구현하기

앞선 데이터에 학습률 변수의 지수 범위를 -6에서 -2로, / 가중치 감소 변수의 지수 범위를 -8에서 -4로 지정하고 / 총 100개의 매개변수 쌍에 대한 train, test 정확도를 그래프로 그려보면 / 다음과 같은 모양새의 그래프를 얻을 수 있습니다. / 
현재 정확도에 따라 내림차순으로 그래프가 정렬되어 있는데 / 여덟번째까지는 test 데이터에 대한 정확도를 나타낸 파란 선이 / 비슷한 수준에서 끝이 납니다. / 
이때의 hyper-parameter 값들을 보면

학습률은 10에 -3, -2승 구간이 많으며 / 가중치 감소에 대한 변수값은 10에 -5승에서 -7승에 퍼져있는 것을 알 수 있습니다. / 
이를 토대로 다음 학습률의 범위는 10에 -4승에서 -1승으로 / 가중치 감소에 대한 범위는 -8승에서 -5승 정도로 범위를 줄여나갈 수 있습니다.

이렇게 가중치에 이여 / 정확도에 영향을 주는 hyper-parameter에 대한 최적화에 대해 알아보았습니다. / 
이상으로 챕터 6의 발표를 마칩니다. / 감사합니다.
