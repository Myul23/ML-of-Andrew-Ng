# [Chapter 7. 합성곱 신경망(CNN)](https://www.miricanvas.com/design/17ywq5)

- [감사합니다, 스앵님](https://je-d.tistory.com/entry/%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9DCNN)

이어서 7장 합성곱 신경망에 대한 내용입니다. / 
CNN은 Convolutional Neural Network의 줄임말로 / 이미지 인식 분야에서 굉장히 자주 등장하는 기법입니다.

## 7.1 전체 구조

지금까지의 신경망은 / 인접하는 계층의 모든 뉴런과 / 직접적으로 결합되어 있었습니다. / 
다시 / 행렬곱을 통해 / 하나의 노드가 / 이전 층의 모든 노드에 접근할 수 있었습니다. / 
이를 완전연결이라고 하고 / Affine 계층을 통해 구성했습니다.

이와 달리 CNN에는 / Affine 대신에 합성곱 계층이 / Activation 계층 뒤에 풀링 계층이 / 새롭게 도입된 형태로 / Convolutional, Activation, Pooling으로 데이터가 흐릅니다. / 
이렇게 완전연결 신경망과 CNN은 비슷해보이지만, / CNN이 각 계층 사이에 입체적인 데이터가 흐른다는 점에서 이 둘은 상당히 다릅니다.

## 7.2 합성곱 계층

### 7.2.1 완전연결 계층의 문제점

다차원 데이터는 / 각 데이터의 위치도 중요한 정보가 됩니다. /
3차원 이미지 데이터를 생각해보면,

선이 그려진 그림은 / 주변의 같은 픽셀값을 갖는 것이 있을 가능성이 높습니다.
그러나 완전연결 계층은 / 데이터를 1차원으로 축소시키면서 / 위치 정보를 잃어버립니다.
결과적으로 완전연결 계층은 / 데이터의 형상을 무시하고 / 모든 입력 데이터를 같은 차원의 뉴런으로 취급하여 / 형상에 담긴 정보를 살릴 수 없습니다.

### 7.2.2 합성곱 연산

CNN의 합성곱 연산은 자세히 보면 / 이런 식으로 구성됩니다.

이때 입출력 데이터를 통틀어 특징 맵이라 부르는데 / 이 입력 특징 맵에 필터 or 커널 연산을 통해 / 가중치와 곱해지게 됩니다. / 
이때 이번에 필터와 곱해지는 입력 특징 맵의 부분 행렬을 / 윈도우라 칭합니다. / 
예를 통해 보자면 

다음 연산에서 회색 부분은 / 이번 순서에서 필터와 곱해질 범위로 윈도우라 부릅니다.

그리고 스칼라 연산처럼 / 편향 또한 이용할 수 있습니다.

### 7.2.3 패딩

앞서처럼 합성곱 연산을 진행하면 / 출력 데이터의 형상이 입력 데이터의 형상과 달리 작아집니다. / 
그리고 중간 값들이 연산에 다수 참가하는 것과 비교해 / 바깥쪽에 위치한 값들은 상대적으로 연산에 덜 참여하게 됩니다.

이것들을 막고자 패딩이라는 것을 실시합니다. / 
패딩이란 데이터의 바깥쪽을 특정값으로 두르는 것을 의미하며 / 이를 통해 입력 특징 맵의 형상을 유지하게 됩니다. / 
예시에서는 0으로 한 번만 둘렀지만, / 필요에 따라 다른 값을 이용할 수도 있고 / 두 줄 이상을 두를 수도 있습니다.

### 7.2.4 스트라이드

이 그림을 다시 보면 / 윈도우가 오른쪽으로 한 칸씩 그리고 아래로 한 칸씩 / 이동했음을 알 수 있습니다. / 그러나 꼭 한 칸씩 이동해야 하는 것은 아닙니다. 

이렇게 2칸씩 이동해서 출력 특징 맵의 형상을 줄일 수도 있습니다. / 
이때 윈도우가 움직이는 칸의 거리를 스트라이드라고 합니다.

앞선 패딩과 스트라이드의 값을 달리하면 / 출력 특징 맵의 형상을 입력에 비해 줄이거나 유지할 수 있었습니다. / 
이렇게 입력 데이터의 형상, 패딩, 스트라이드에 따라 / 나타나는 출력 특징 맵의 형상은 다음과 같이 수식화할 수 있습니다.

이 수식의 결과값은 / 당연히 형상을 구성하는 수이기 때문에 / 모든 양수여야 합니다.ㄴ

### 7.2.5 3차원 데이터의 합성곱 연산

앞선 예시들은 이미지 데이터이더라도 / 흑백으로 되어 채널이 하나인 데이터였습니다.

이를 확장하면 / 흑백이 아닌 이미지에 대해선 / 각 채널마다 대응하는 필터를 갖고 / 같은 위치의 값을 더해서 출력으로 넘깁니다.

### 7.2.6 블록으로 생각하기

채널의 수를 더 늘려 생각하면 / 이런 식의 블럭으로 표현할 수 있습니다. / 
더 나아가 출력 데이터를 늘리고자

또 다른 필터( 무더기)를 이용할 수도 있습니다.

### 7.2.7 배치 처리 -> 그냥 배치 처리를 하면 한 번에 N개를 연산시켜야 한다고.

그리고 편향도 표시해주고 / 배치를 이용하듯 / 적지만 다량의 데이터를 한 번에 학습시키면 / 이런 식으로 입체 데이터가 모형을 따라 흐르게 됩니다.

여기까지 Convolutional, 합성곱 계층에 대한 내용이었습니다.
